{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This notebook was created for Christopher Carroll's discussion of \"Overpersistence Bias in Individual Income Expectations and its Aggregate Implications\" by Filip Rozsypal and Kathrin Schlafmann on July 13, 2018 at [The NBER Behavioral Macroeconomics Conference](http://papers.nber.org/sched/SI18EFBEM).  Thanks to Matthew White and Tiphane Magne of the University of Delaware for assistance in preparing this presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"6\"><b><center> Beliefs About Income Dynamics</center></b></font>\n",
    "## Central Element in _All_ Our Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "| Variable Names | .  | Definition | \n",
    "| --- :| --- | :--- |\n",
    "| $p$ | - | permanent (noncapital) income | \n",
    "| $\\Gamma=(1+\\gamma)$ | - | _believed_ growth factor: $p_{t+1}=\\Gamma p_{t}$ |\n",
    "| $m$ | - | market wealth |\n",
    "| $h$ | - | human wealth |\n",
    "\n",
    "[Benchmark perfect foresight model](http://econ.jhu.edu/people/ccarroll/public/lecturenotes/consumption/PerfForesightCRRA): (CRRA utility, time preference, etc) yield $\\kappa$ such that:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "c & = & (m + h) \\kappa\n",
    "\\end{eqnarray}\n",
    "\n",
    "In infinite horizon case, human wealth $h$ is:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "h & = & \\frac{p}{1-R/\\Gamma}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b><center> Quantitatively ...</center></b></font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# This cell does the calculations supporting the cell below\n",
    "# Click the \"Run\" button immediately above the notebook in order to execute the contents of any cell\n",
    "# WARNING: Each cell in the notebook relies upon results generated by previous cells\n",
    "#   The most common problem beginners have is to execute a cell before all its predecessors\n",
    "#   If you do this, you can restart the kernel (see the \"Kernel\" menu above) and start over\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import HARK \n",
    "from time import clock\n",
    "from copy import deepcopy\n",
    "mystr = lambda number : \"{:.4f}\".format(number)\n",
    "from HARK.utilities import plotFuncs\n",
    "\n",
    "# This cell defines a parameter dictionary. You can expand it if you want to see what that looks like.\n",
    "\n",
    "from HARK.ConsumptionSaving.ConsIndShockModel import PerfForesightConsumerType\n",
    "PF_dictionary0 = {\n",
    "    'CRRA' : 1.01,\n",
    "    'DiscFac' : 0.99,\n",
    "    'Rfree' : 1.03,\n",
    "    'LivPrb' : [1.0],\n",
    "    'PermGroFac' : [1.02],\n",
    "    'T_cycle' : 1,\n",
    "    'cycles' : 0,\n",
    "    'AgentCount' : 10000\n",
    "}\n",
    "\n",
    "# To those curious enough to open this hidden cell, you might notice that we defined\n",
    "# a few extra parameters in that dictionary: T_cycle, cycles, and AgentCount. Don't\n",
    "# worry about these for now.\n",
    "\n",
    "PFexample0 = PerfForesightConsumerType(**PF_dictionary0) \n",
    "# the asterisks ** basically says \"here come some arguments\" to PerfForesightConsumerType\n",
    "PFexample0.solve() # Solve with those parameters\n",
    "m = 4 # market wealth includes current income \n",
    "p = 1 # normalize permanent income to one\n",
    "# Extract interest and growth factors used in solution\n",
    "R = PFexample0.Rfree \n",
    "PermGroFac0 = PFexample0.PermGroFac[0]\n",
    "h0 = 1/(1-PermGroFac0/R)\n",
    "c0 = np.asscalar(PFexample0.solution[0].cFunc(m)) # Evaluate cFunc at m\n",
    "y0 = 1+(m-1)*(R-1) # Total income = noncapital plus capital income\n",
    "s0 = (y0 - c0)/y0 \n",
    "# print y0,h0,c0,s0\n",
    "\n",
    "PF_dictionary1 = deepcopy(PF_dictionary0)\n",
    "PermGroFac1 = 1.025\n",
    "PF_dictionary1['PermGroFac'] = [PermGroFac1]\n",
    "\n",
    "# Construct and solve consumer with new growth rate\n",
    "PFexample1 = PerfForesightConsumerType(**PF_dictionary1) \n",
    "PFexample1.solve()\n",
    "h1 = 1/(1-PermGroFac1/R)\n",
    "c1 = np.asscalar(PFexample1.solution[0].cFunc(m))\n",
    "y1 = 1+(m-1)*(R-1)\n",
    "s1 = (y1 - c1)/y1\n",
    "# print h1,y1,c1,s1\n",
    "\n",
    "PF_dictionary2 = deepcopy(PF_dictionary0)\n",
    "PermGroFac2 = 0.0001\n",
    "PF_dictionary1['PermGroFac'] = [PermGroFac2]\n",
    "PFexample2 = PerfForesightConsumerType(**PF_dictionary2) \n",
    "PFexample2.solve()\n",
    "h2 = p/(1-PermGroFac2/R)\n",
    "c2 = np.asscalar(PFexample2.solution[0].cFunc(m))\n",
    "y2 = 1+(m-1)*(R-1)\n",
    "s2 = (y2 - c2)/y2\n",
    "#print y2,h2,c2,s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What difference do _beliefs_ about $\\Gamma$ make?\n",
    "\n",
    "Consider:\n",
    "* Person (or SOE) with assets-to-income ratio $3$\n",
    "* Calibrate $\\Gamma = 1.03$, $R = 1.02$\n",
    "   * Pick other parameters so saving rate $s = 0.01$\n",
    "\n",
    "\n",
    "|  <br> _believed_ Growth Factor $\\Gamma~~~$  | Income <br> $y$ |Consumption <br> $c$ = $(m+h)\\kappa$ | Saving Out of Income <br> $s$ = $ (y - c)/y $ <br> |\n",
    "| :---: | :---: | --- | ---: |\n",
    "| $\\Gamma=1.020$ | 1.09 | 1.08 | 0.01 |\n",
    "| $\\Gamma=1.025$ | 1.09 | 2.13 | -0.95 |\n",
    "| $\\Gamma=0.000$ | 1.09 | 0.04 | 0.96 |\n",
    "\n",
    "Uncertainty, liquidity constraints, finite horizons, hyperbolic discounting, etc etc?\n",
    "* Reduce magnitudes substantially\n",
    "* Still: $c$ is _hugely_ sensitive to beliefs about $y$ dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b><center>Tradition: Calibrate Beliefs To Match $y$ Facts</center></b></font>\n",
    "\n",
    "### Large Literature On $y$ Dynamics\n",
    "\n",
    "Relaxes assumption that $p$ is permanent; it could merely have _persistence_ $\\rho \\leq 1$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    " \\log p_{t+1} & = & \\gamma + \\rho \\log p_{t} + \\psi_{t+1}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "| Paper | Data Source | Observations | $\\rho$ <br> (Annual)| Comment |\n",
    "| :--- | --- | --- | --- | :--- |\n",
    "| **Storesletten, Telmer, Yaron (STY) <br> (2004, JME)** | PSID | 4000 | 0.91 | The Authors' Oracle |\n",
    "| Abowd and Card <br> (Econometrica, 1989) | PSID | 4000 | 1.00 | Wages (not income) |\n",
    "| Sabelhaus and Song <br> (JME, 2010) | Social Security | 160,000,000 | 1.00 | Throughout |\n",
    "| Kaplan <br> (QE, 2012) | PSID | 4000 | 0.97 | Table 4, col 3, Appendix E, p. 515 |\n",
    "| Hryshko <br> (QE, 2012) | PSID | 4000 | 0.99 or 1.00 | Table 13, $\\phi$ |\n",
    "| Bricker et al <br> (BPEA, 2013 ) | IRS | 120,000,000 | 0.96-0.98 | Table 4, p. 96 |\n",
    "\n",
    "Learned since STY (thanks to millions of datapoints):\n",
    "1. \"transitory\" component is MA(1) annually\n",
    "   * which is implied by time aggregation, cf Muth (1960)\n",
    "1. Size of shocks varies by age ([Sabelhaus and Song]()):\n",
    "   * [Sabelhaus-And-Song-Variances-By-Age](https://github.com/llorracc/Figures/blob/master/Sabelhaus-Song-Income-Variances-By-Age.jpg#raw-url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beliefs $\\Rightarrow$ Saving $\\Rightarrow$ Wealth $\\Rightarrow$ Macro\n",
    "\n",
    "* Capturing _distribution_ of wealth is first-order \n",
    "  * Monetary Policy (HANK literature: Kaplan, Violante, Moll, Mitman, ...)\n",
    "  * Fiscal Policy (Mian and Sufi, Steinsson and Nakamura, Chodorow-Reich, Ganong and Noel, ...)\n",
    "  \n",
    "... because people with low wealth have high MPC's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b><center>But: Beliefs ($\\hat{\\rho}$) = Truth ($\\rho$) Doesn't Work ...</center></b></font>\n",
    "\n",
    "### If $\\hat{\\rho} = \\rho = 1$\n",
    "\n",
    "![Lorenz Curves](http://www.econ2.jhu.edu/people/ccarroll/Papers/cstMPCxc/CumWLevSCFCastanedaAndDistSevenPermPlot.png)\n",
    "(from [cstwMPC](http://www.econ2.jhu.edu/people/ccarroll/papers/cstwMPC/))\n",
    "\n",
    "\n",
    "* SCF data (Solid locus)\n",
    "* $\\beta$-Point: homogeneous $\\beta$\n",
    "   * Wealth inequality too small: roughly matches $p$ inequality\n",
    "* $\\beta$-Dist:\n",
    "   * Heterogeneous time preference rates $\\beta \\in [0.94, 0.98]$\n",
    "   * $\\Rightarrow$ wealth inequality >> $p$ inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b><center> ... Unless \"Truth\" (for everyone) is $\\rho=0.91$ ?</center></b></font>\n",
    "\n",
    "Inequality in wealth greater than $p$ because:\n",
    "\n",
    "* $p$-\"rich\" save _a lot_ because they are _very_ pessimistic\n",
    "   * $\\Rightarrow$ they are _even more_ wealth-\"rich\" than $p$-rich\n",
    "* $p$-\"poor\" don't save because _very_ optimistic\n",
    "   * $\\Rightarrow$ they are _even more_ wealth-\"poor\" than $p$-poor\n",
    "\n",
    "I never bought this story:\n",
    "   * Large literature: High-$p$ people more *optimistic*\n",
    "      * About practically everything\n",
    "      * Inflation, Unemployment, ...\n",
    "   * Until this paper, couldn't _prove_ it for $\\mathbb{E}[\\Delta \\log y_{t+1}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--- <font size=\"6\"><b><center> ... But Even with $\\hat{\\rho}=\\rho=0.92$ </center></b></font> --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"6\"><b><center> Authors: Data on Income Growth Expectations Exist</center></b></font>\n",
    "\n",
    "$\\tiny{.}$\n",
    "\n",
    "<font size=\"6\"><b><center>Let's Use Them!</center></b></font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 0: [Rich save more](https://www.econ2.jhu.edu/people/ccarroll/Lectures/RichSaveSlides.pdf) because more pessimistic?  NO!\n",
    "\n",
    "$\\tiny{.}$\n",
    "<font size=\"3\"><b><center>Expected Growth By Income Decile</center></b></font>\n",
    "\n",
    "![RS-Fig-6b.jpg](attachment:RS-Fig-6b.jpg)\n",
    "\n",
    "<font size=\"3\"><b><center>Expectation Errors (Figure 2b)</center></b></font>\n",
    "\n",
    "![RS-Fig-2b.jpg](attachment:RS-Fig-2b.jpg)\n",
    "\n",
    "But: Authors don't really _do_ anything with this result.  They should!\n",
    "\n",
    "# Authors' Agenda? Part 1\n",
    "1. Suppose Everybody is Equally Wrong\n",
    "   * Assume true $\\rho = 0.91$ (convert to quarterly process)\n",
    "   * Find $\\hat{\\rho}$ that matches expectations and realizations \"data\" best\n",
    "\n",
    "Data?  _very_ complicated\n",
    "\n",
    "Best case overlap between beliefs $\\mathbb{B}$ and realization:\n",
    "   * $\\mathbb{B}[Y_{2019,\\text{Jul}}/Y_{2018,\\text{Jul}}]$\n",
    "   * Actual $Y_{2018}/Y_{2017}$\n",
    "\n",
    "1. Options:\n",
    "   * Assume you (RS) know the \"true\" $y$ process\n",
    "      * $\\rho=0.91$, magnitudes of two shocks, other stuff \n",
    "      * You can then forecast Jan-July 2019 (?)\n",
    "   * Impute to me average growth _of other people_ for Jan-July 2019\n",
    "   * Very hard to follow exactly what they do\n",
    "       * Please provide a concrete example\n",
    "\n",
    "Sniff test:\n",
    "1. Authors' calculated \"realized\" growth numbers seem implausible\n",
    "   * Half experience growth $> 8$ percent\n",
    "   * Only 10 percent have income declines\n",
    "   * How could these numbers average to sample truth (say, 3 percent)\n",
    "   * Suggestion:\n",
    "      * By income decile, compare to realized growth from PSID\n",
    "2. Survey expectations seem more sensible than authors' calculations of \"realized\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Puzzle\n",
    "\n",
    "Conflict with [\"Understanding Permanent and Temporary Income Shocks\"](http://libertystreeteconomics.newyorkfed.org/2017/11/understanding-permanent-and-temporary-income-shocks.html) by Karahan et al using NY Fed's new [Survey of Consumer Expectations](https://www.newyorkfed.org/microeconomics/sce)\n",
    "\n",
    "![Income-Realizations-Versus-Expectations.jpg](attachment:Income-Realizations-Versus-Expectations.jpg)\n",
    "\n",
    "Cryptic footnote 36 says impossible to make this histogram using SCE data ...\n",
    "<!--- Be careful what you wish for --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authors' Agenda, Part 2\n",
    "\n",
    "1. Start with model that assumes:\n",
    "\n",
    "|  Kind | $\\rho$ |\n",
    "| --- | --- |\n",
    "| Believed | 0.93 ($\\approx 0.9831^4$) |\n",
    "| Truth    | 0.91 ($\\approx 0.9774^4$) |\n",
    "\n",
    "2. Ask it to match dist'n of liquid assets, durables\n",
    "   * \"Models like [ours] are not able to match [wealth distribution] without adding heterogeneity\"\n",
    "   * Why _not_ add heterogeneity, match wealth distribution, and see if results change?\n",
    "3. Implications if $\\hat{\\rho}$ changed to (their assumed) $\\rho$:\n",
    "   * Poor people would be less pessimistic, want to borrow more\n",
    "   * MPC a bit lower\n",
    "   * Effects of changes in credit would be smaller\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Critique: What if $\\rho \\approx 1$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Econ-ARK](http://econ-ark.org) can do this (without durables, so far)\n",
    "\n",
    "Specific Exercise:\n",
    "0. Starting point: Model that matches wealth distribution by $\\beta$-Dist\n",
    "   * where $\\rho=1$ and $\\hat{\\rho}=\\rho$\n",
    "0. What if $\\hat{\\rho} = \\rho = 0.91$?\n",
    "   * Beliefs match truth, but serious mean reversion\n",
    "0. We change beliefs to match authors' claim $\\hat{\\rho} = 0.93 > \\rho = 0.91$\n",
    "   * Simulate effects on wealth distribution\n",
    "0. Now switch it: assume $\\hat{\\rho} = 0.91 < \\rho = 0.93$\n",
    "   * Simulate effects on wealth distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Initial imports and notebook setup, click arrow to show\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "from HARK.ConsumptionSaving.ConsGenIncProcessModel import *\n",
    "import HARK.ConsumptionSaving.ConsumerParameters as Params\n",
    "\n",
    "from HARK.utilities import approxUniform, getLorenzShares, calcSubpopAvg\n",
    "from time import clock\n",
    "mystr = lambda number : \"{:.4f}\".format(number)\n",
    "\n",
    "# Make a subclass of PersistentShockConsumerType including the MPC \n",
    "class PersistentShockConsumerTypeX(PersistentShockConsumerType):\n",
    "    def getControls(self):\n",
    "        cLvlNow = np.zeros(self.AgentCount) + np.nan\n",
    "        MPCnow = np.zeros(self.AgentCount) + np.nan\n",
    "        for t in range(self.T_cycle):\n",
    "            these = t == self.t_cycle\n",
    "            cLvlNow[these] = self.solution[t].cFunc(self.mLvlNow[these],self.pLvlNow[these])\n",
    "            MPCnow[these]  =self.solution[t].cFunc.derivativeX(self.mLvlNow[these],self.pLvlNow[these])\n",
    "        self.cLvlNow = cLvlNow\n",
    "        self.MPCnow  = MPCnow\n",
    "        \n",
    "# Define dictionary to make instance of PersistentShockConsumerType for infinite horizon model\n",
    "BaselineDict = {\n",
    "        \"CRRA\": 2.0,                           # Coefficient of relative risk aversion\n",
    "        \"Rfree\": 1.01/(1.0 - 1.0/160.0),       # Interest factor on assets\n",
    "        \"DiscFac\": 0.97,                       # Default intertemporal discount factor\n",
    "        \"LivPrb\" : [1.0 - 1.0/160.0],          # Survival probability\n",
    "        \"AgentCount\" : 10000,                  # Number of agents of this type (only matters for simulation)\n",
    "        \"IndL\": 10.0/9.0,                      # Labor supply per individual (constant)\n",
    "        \"aNrmInitMean\" : np.log(0.00001),      # Mean of log initial assets (only matters for simulation)\n",
    "        \"aNrmInitStd\"  : 0.0,                  # Standard deviation of log initial assets (only for simulation)\n",
    "        \"pLvlInitMean\" : 0.0,                  # Mean of log initial permanent income (only matters for simulation)\n",
    "        \"pLvlInitStd\"  : 0.0,                  # Standard deviation of log initial permanent income (only matters for simulation)\n",
    "        \"PermGroFacAgg\" : 1.0,                 # Aggregate permanent income growth factor (only matters for simulation)\n",
    "        \"T_age\" : 400,                         # Age after which simulated agents are automatically killed\n",
    "        \"T_cycle\" : 1,                         # Number of periods in the cycle for this agent type\n",
    "        \"T_sim\":1200,                          # Number of periods to simulate (idiosyncratic shocks model, perpetual youth)\n",
    "        \"aXtraMin\" : 0.001,                    # Minimum end-of-period \"assets above minimum\" value\n",
    "        \"aXtraMax\" : 30,                       # Maximum end-of-period \"assets above minimum\" value               \n",
    "        \"aXtraExtra\" : [0.005,0.01],           # Some other value of \"assets above minimum\" to add to the grid\n",
    "        \"aXtraNestFac\" : 3,                    # Exponential nesting factor when constructing \"assets above minimum\" grid\n",
    "        \"aXtraCount\" : 48,                     # Number of points in the grid of \"assets above minimum\"\n",
    "        \"PermShkCount\" : 7,                    # Number of points in discrete approximation to permanent income shocks\n",
    "        \"TranShkCount\" : 7,                    # Number of points in discrete approximation to transitory income shocks\n",
    "        \"PermShkStd\" : [(0.01*4/11)**0.5],     # Standard deviation of permanent shocks to income\n",
    "        \"TranShkStd\" : [(0.01*4)**0.5],        # Standard deviation of transitory shocks to income\n",
    "        \"UnempPrb\" : 0.05,                     # Probability of unemployment while working\n",
    "        \"UnempPrbRet\" : 0.005,                 # Probability of \"unemployment\" while retired\n",
    "        \"IncUnemp\" : 0.3,                      # Unemployment benefits replacement rate\n",
    "        \"IncUnempRet\" : 0.0,                   # \"Unemployment\" benefits when retired\n",
    "        \"tax_rate\" : 0.0,                      # Flat income tax rate\n",
    "        \"T_retire\" : 0,                        # Period of retirement (0 --> no retirement)\n",
    "        \"BoroCnstArt\" : 0.0,                   # Artificial borrowing constraint; imposed minimum level of end-of period assets\n",
    "        \"CubicBool\" : False,                   # Use cubic spline interpolation when True, linear interpolation when False\n",
    "        \"vFuncBool\" : True,                    # Whether to calculate the value function during solution    \n",
    "        \"cycles\": 0,                           # Make this type have an infinite horizon\n",
    "        \"pLvlPctiles\" : np.concatenate(([0.001, 0.005, 0.01, 0.03], np.linspace(0.05, 0.95, num=19),[0.97, 0.99, 0.995, 0.999])),\n",
    "        \"PermGroFac\" :[1.000**0.25],           # Permanent income growth factor (no perm growth)                   \n",
    "        \"PrstIncCorr\": 0.99,                   # Serial correlation coefficient for persistence of income\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Attempt to speed solution by shrinking simulation size\n",
    "BaselineDict['AgentCount'] = 500\n",
    "# BaselineDict['CRRA'] = 2.0\n",
    "BaselineDict['T_sim'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Defines runRoszypalSchlaffmanExperiment: solve and simulate a consumer misperceiving the correlation of persistent income shocks\n",
    "def runRoszypalSchlaffmanExperiment(CorrAct, CorrPcvd, DiscFac_center, DiscFac_spread, numTypes, simPeriods):\n",
    "    '''\n",
    "    Solve and simulate a consumer type who misperceives the extent of serial correlation\n",
    "    of persistent shocks to income.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    CorrAct : float\n",
    "        Serial correlation coefficient for *actual* persistent income.\n",
    "    CorrPcvd : float\n",
    "        List or array of *perceived* persistent income serial correlation\n",
    "    DiscFac_center : float\n",
    "        A measure of centrality for the distribution of the beta parameter, DiscFac.\n",
    "    DiscFac_spread : float\n",
    "        A measure of spread or diffusion for the distribution of the beta parameter.\n",
    "    numTypes: int\n",
    "        Number of different types of agents (distributed using DiscFac_center and DiscFac_spread)\n",
    "    simPeriods: int\n",
    "        Number of periods to simulate before calculating distributions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    AggWealthRatio: float\n",
    "        Ratio of Aggregate wealth to income.\n",
    "    Lorenz: numpy.array\n",
    "        A list of two 1D array representing the Lorenz curve for assets in the most recent simulated period.\n",
    "    Gini: float\n",
    "        Gini coefficient for assets in the most recent simulated period.\n",
    "    Avg_MPC: numpy.array\n",
    "        Average marginal propensity to consume by income quintile in the latest simulated period.\n",
    "    \n",
    "    '''     \n",
    "    \n",
    "    # Make a dictionary to construct our consumer type\n",
    "    ThisDict = copy(BaselineDict)\n",
    "    ThisDict['PrstIncCorr'] = CorrAct\n",
    "    \n",
    "    # Make a N=numTypes point approximation to a uniform distribution of DiscFac\n",
    "    DiscFac_list = approxUniform(N=numTypes,bot=DiscFac_center-DiscFac_spread,top=DiscFac_center+DiscFac_spread)[1]\n",
    "    \n",
    "    type_list = []\n",
    "    # Make a PersistentShockConsumerTypeX for each value of beta saved in DiscFac_list\n",
    "    for i in range(len(DiscFac_list)):    \n",
    "        ThisDict['DiscFac'] = DiscFac_list[i]    \n",
    "        ThisType = PersistentShockConsumerTypeX(**ThisDict)\n",
    "              \n",
    "        # Make the consumer *believe* he will face a different level of persistence\n",
    "        ThisType.PrstIncCorr = CorrPcvd\n",
    "        ThisType.updatepLvlNextFunc() # *thinks* E[p_{t+1}] as a function of p_t is different than it is\n",
    "    \n",
    "        # Solve the consumer's problem with *perceived* persistence \n",
    "        ThisType.solve()\n",
    "    \n",
    "        # Make the consumer type experience the true level of persistence during simulation\n",
    "        ThisType.PrstIncCorr = CorrAct\n",
    "        ThisType.updatepLvlNextFunc()\n",
    "    \n",
    "        # Simulate the agents for many periods\n",
    "        ThisType.T_sim = simPeriods\n",
    "        #ThisType.track_vars = ['cLvlNow','aLvlNow','pLvlNow','MPCnow']\n",
    "        ThisType.initializeSim()\n",
    "        ThisType.simulate()\n",
    "        type_list.append(ThisType)\n",
    "    \n",
    "    # Get the most recent simulated values of X = cLvlNow, MPCnow, aLvlNow, pLvlNow for all types   \n",
    "    cLvl_all = np.concatenate([ThisType.cLvlNow for ThisType in type_list])\n",
    "    aLvl_all = np.concatenate([ThisType.aLvlNow for ThisType in type_list])\n",
    "    MPC_all = np.concatenate([ThisType.MPCnow for ThisType in type_list])\n",
    "    pLvl_all = np.concatenate([ThisType.pLvlNow for ThisType in type_list])\n",
    "    \n",
    "    # The ratio of aggregate assets over the income\n",
    "    AggWealthRatio = np.mean(aLvl_all) / np.mean(pLvl_all)\n",
    "\n",
    "    # first 1D array: Create points in the range (0,1)\n",
    "    wealth_percentile = np.linspace(0.001,0.999,201)\n",
    "\n",
    "    # second 1D array: Compute Lorenz shares for the created points\n",
    "    Lorenz_init = getLorenzShares(aLvl_all, percentiles=wealth_percentile)\n",
    "\n",
    "    # Stick 0 and 1 at the boundaries of both arrays to make it inclusive on the range [0,1]\n",
    "    Lorenz_init = np.concatenate([[0],Lorenz_init,[1]])\n",
    "    wealth_percentile = np.concatenate([[0],wealth_percentile,[1]])\n",
    "    \n",
    "    # Create a list of wealth_percentile 1D array and Lorenz Shares 1D array\n",
    "    Lorenz  = np.stack((wealth_percentile, Lorenz_init))\n",
    "\n",
    "    # Compute the Gini coefficient\n",
    "    Gini = 1.0 - 2.0*np.mean(Lorenz_init[1])\n",
    "    \n",
    "    # Compute the average MPC by income quintile in the latest simulated period\n",
    "    Avg_MPC = calcSubpopAvg(MPC_all, pLvl_all, cutoffs=[(0.0,0.2), (0.2,0.4),  (0.4,0.6), (0.6,0.8), (0.8,1.0)])\n",
    "    \n",
    "    return AggWealthRatio, Lorenz, Gini, Avg_MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Sync/Sys/OSX/linked/root/usr/local/bin/anaconda/lib/python3.6/site-packages/HARK/interpolation.py:782: RuntimeWarning: invalid value encountered in less\n",
      "  below_lower_bound = x < self.x_list[0]\n",
      "/Volumes/Sync/Sys/OSX/linked/root/usr/local/bin/anaconda/lib/python3.6/site-packages/HARK/interpolation.py:1743: RuntimeWarning: All-NaN slice encountered\n",
      "  y = np.nanmax(fx,axis=1)\n",
      "/Volumes/Sync/Sys/OSX/linked/root/usr/local/bin/anaconda/lib/python3.6/site-packages/HARK/interpolation.py:790: RuntimeWarning: invalid value encountered in greater\n",
      "  above_upper_bound = x > self.x_list[-1]\n",
      "/Volumes/Sync/Sys/OSX/linked/root/usr/local/bin/anaconda/lib/python3.6/site-packages/HARK/interpolation.py:1812: RuntimeWarning: All-NaN slice encountered\n",
      "  f = np.nanmin(temp,axis=1)\n",
      "/Volumes/Sync/Sys/OSX/linked/root/usr/local/bin/anaconda/lib/python3.6/site-packages/HARK/ConsumptionSaving/ConsIndShockModel.py:707: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.PatFac/solution_next.MPCmax)\n",
      "/Volumes/Sync/Sys/OSX/linked/root/usr/local/bin/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "# Storesletten, Telmer, Yaron config: CorrPcvd=CorrAct\n",
    "simPeriodsAll = 100\n",
    "DiscFac_cstw=0.9867\n",
    "DiscSpr_cstw=0.0067\n",
    "corrActSTY=0.9774\n",
    "DiscSpr0=0.0\n",
    "numTypes1=1\n",
    "DiscSpr_STY=0.0\n",
    "corrPcvdSTY=corrActSTY\n",
    "AggWealthRatio, Lorenz, Gini, Avg_MPC = runRoszypalSchlaffmanExperiment(corrActSTY\n",
    "                                                                        , corrPcvdSTY\n",
    "                                                                        , DiscFac_cstw\n",
    "                                                                        , DiscSpr0\n",
    "                                                                        , numTypes1\n",
    "                                                                        , simPeriodsAll)\n",
    "\n",
    "# # Plot the Lorenz curve\n",
    "# plt.xlabel('Wealth percentile')\n",
    "# plt.ylabel('Cumulative wealth share')\n",
    "# plt.xlim([0.,1.])\n",
    "# plt.ylim([0.,1.])\n",
    "\n",
    "# #print('The Lorenz curve for assets is')\n",
    "\n",
    "# #plt.plot(Lorenz[0],Lorenz[1])\n",
    "# #plt.show()\n",
    "\n",
    "# #print('The aggregate wealth to income ratio is ' + str(AggWealthRatio))\n",
    "# # print('The Gini Coefficient for assests is ' + str(Gini))\n",
    "# print('The average MPC by income quintile is ' + str(Avg_MPC))\n",
    "\n",
    "AggWealthRatioSTY, LorenzSTY, GiniSTY, Avg_MPCSTY  = AggWealthRatio, Lorenz, Gini, Avg_MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# cstwMPC except CorrPcvd=corrPcvdSTY\n",
    "simPeriodsAll = 100\n",
    "DiscFac_cstw=0.9867\n",
    "DiscSpr_cstw=0.0067\n",
    "corrActcstw=0.995\n",
    "numTypescstw=7\n",
    "# (DiscFac Rfree)^{1/\\rho}/\\Gamma0 = ((DiscFac + x) Rfree)^{1/\\rho}/\\Gamma1\n",
    "# (DiscFac Rfree)\\Gamma_0^\\rho = ((DiscFac (1+ x) Rfree)(\\Gamma0-0.07)^{\\rho}\n",
    "# \\Gamma_0^\\rho = x Rfree)(\\Gamma0-0.07)^{\\rho}\n",
    "# \\Gamma_0 = (x Rfree)^{1/\\rho}(\\Gamma0-0.07)\n",
    "# 1 = (x Rfree)^{1/\\rho}(1-0.07/\\Gamma)\n",
    "# (1-0.07/\\Gamma)^{-1} = (x Rfree)\n",
    "# (1-0.07/\\Gamma)^{-1}/Rfree = x\n",
    "\n",
    "                                                 \n",
    "AggWealthRatio, Lorenz, Gini, Avg_MPC = runRoszypalSchlaffmanExperiment(corrActSTY\n",
    "                                                                        , corrPcvdSTY\n",
    "                                                                        , DiscFac_cstw-(1-corrPcvdSTY)\n",
    "                                                                        , DiscSpr_cstw\n",
    "                                                                        , numTypescstw\n",
    "                                                                        , simPeriodsAll)\n",
    "\n",
    "# # Plot the Lorenz curve\n",
    "# plt.xlabel('Wealth percentile')\n",
    "# plt.ylabel('Cumulative wealth share')\n",
    "# plt.xlim([0.,1.])\n",
    "# plt.ylim([0.,1.])\n",
    "\n",
    "# #print('The Lorenz curve for assets is')\n",
    "\n",
    "# #plt.plot(Lorenz[0],Lorenz[1])\n",
    "# #plt.show()\n",
    "\n",
    "# #print('The aggregate wealth to income ratio is ' + str(AggWealthRatio))\n",
    "# # print('The Gini Coefficient for assests is ' + str(Gini))\n",
    "# print('The average MPC by income quintile is ' + str(Avg_MPC))\n",
    "\n",
    "AggWealthRatio_cstwRS, Lorenz_cstwRS, Gini_cstwRS, Avg_MPC_cstwRS  = AggWealthRatio, Lorenz, Gini, Avg_MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Roszypal-Schlafmann values: CorrPcvd>CorrAct\n",
    "corrActRS=0.9774\n",
    "corrPcvdRS=0.9831\n",
    "\n",
    "AggWealthRatio, Lorenz, Gini, Avg_MPC = runRoszypalSchlaffmanExperiment(corrActRS, corrPcvdRS, DiscFac_cstw, DiscSpr0, numTypes1, simPeriodsAll)\n",
    "\n",
    "# # Plot the Lorenz curve\n",
    "# plt.xlabel('Wealth percentile')\n",
    "# plt.ylabel('Cumulative wealth share')\n",
    "# plt.xlim([0.,1.])\n",
    "# plt.ylim([0.,1.])\n",
    "\n",
    "# print('The Lorenz curve for assets is')\n",
    "\n",
    "# #plt.plot(Lorenz[0],Lorenz[1])\n",
    "# #plt.show()\n",
    "\n",
    "# #print('The aggregate wealth to income ratio is ' + str(AggWealthRatio))\n",
    "# # print('The Gini Coefficient for assests is ' + str(Gini))\n",
    "# print('The average MPC by income quintile is ' + str(Avg_MPC))\n",
    "\n",
    "# AggWealthRatioRS, LorenzRS, GiniRS, Avg_MPCRS = AggWealthRatio, Lorenz, Gini, Avg_MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get SCF data and cstwMPC sims\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "f = open('/Volumes/Data/Job/Discuss/2018-07_NBER_Behavioral-Macro/cstwMPC/Code/Python/Results/LCbetaPointNetWorthLorenzFig.txt','r')\n",
    "my_reader = csv.reader(f,delimiter='\\t')\n",
    "raw_data = list(my_reader)\n",
    "lorenz_percentiles = []\n",
    "scf_lorenz = []\n",
    "beta_point_lorenz = []\n",
    "for j in range(len(raw_data)):\n",
    "    lorenz_percentiles.append(float(raw_data[j][0]))\n",
    "    scf_lorenz.append(float(raw_data[j][1]))\n",
    "    beta_point_lorenz.append(float(raw_data[j][2]))\n",
    "f.close()\n",
    "lorenz_percentiles = np.array(lorenz_percentiles)\n",
    "scf_lorenz = np.array(scf_lorenz)\n",
    "beta_point_lorenz = np.array(beta_point_lorenz)\n",
    "\n",
    "f = open('/Volumes/Data/Job/Discuss/2018-07_NBER_Behavioral-Macro/cstwMPC/Code/Python/IHbetaDistNetWorthLorenzFig.txt','r')\n",
    "my_reader = csv.reader(f,delimiter='\\t')\n",
    "raw_data = list(my_reader)\n",
    "beta_dist_lorenz = []\n",
    "for j in range(len(raw_data)):\n",
    "    beta_dist_lorenz.append(float(raw_data[j][2]))\n",
    "f.close()\n",
    "beta_dist_lorenz = np.array(beta_dist_lorenz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot distribution\n",
    "plt.plot(Lorenz_cstwRS[0],Lorenz_cstwRS[1],color='blue',label='cstw+RS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot the Lorenz curves\n",
    "plt.xlabel('Wealth percentile')\n",
    "plt.ylabel('Cumulative wealth share')\n",
    "plt.xlim([0.,1.])\n",
    "plt.ylim([0.,1.])\n",
    "\n",
    "plt.plot(Lorenz[0],LorenzSTY[1],color='green',label='STY')\n",
    "plt.plot(Lorenz[0],LorenzRS[1],color='red',label='RS')\n",
    "#plt.plot(Lorenz[0],LorenzRSInv[1],color='blue')\n",
    "plt.plot(lorenz_percentiles,scf_lorenz,color='black',label='US Data')\n",
    "plt.plot(Lorenz_cstw[0],Lorenz_cstw[1],color='blue',label='cstw+RS')\n",
    "plt.plot(lorenz_percentiles,beta_dist_lorenz,'--k',linewidth=1.5,label='cstwMPC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottom Lines\n",
    "\n",
    "* $\\rho < \\hat{\\rho}$ decreases wealth inequality\n",
    "   * Because you $p$-immiserize the high-savers\n",
    "   * But effect is not very big\n",
    "* I believe $\\rho \\approx 1$\n",
    "   * If their $\\hat{\\rho} = 0.93$ is right:\n",
    "      * To match wealth, will need HUGE heterogeneity in $\\beta$\n",
    "      * _Highly_ correlated with $p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Conclusion\n",
    "\n",
    "## Areas of Agreement\n",
    "\n",
    "1. Need Better Data!\n",
    "   * Panel data\n",
    "   * Period of growth forecast exact match to observed data\n",
    "   * 'You said $\\mathbb{E}[\\Delta \\log y_{t+1}] < 0$.  Why?'\n",
    "\n",
    "2. Once $\\exists$ good data:\n",
    "   * Calibrate Models to Measured, not Made-Up Expectations\n",
    "\n",
    "## Areas of Improvement\n",
    "\n",
    "* Results of paper _deeply_ dependent on $\\rho=0.91$\n",
    "* I don't buy it; $\\rho = 1$ is closer to truth\n",
    "   * $\\rho=0.91$ and $\\rho=1$ are bookends\n",
    "   * They should do both\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
